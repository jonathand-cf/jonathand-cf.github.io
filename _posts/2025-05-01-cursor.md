---
title: "Run Cursor AI for Free using a local AI"
categories: tutorials
open_new_tab: true
toc_sticky: true
author_profile: false
toc: true
---

Run Cursor AI locally on Windows using LM Studio. _(Untested on Linux or macOS.)_

This is not truly local becouse you are using ngrok as a tunnel so Curser can use the API requests.

### Requirements

- **Cursor**: [Download Cursor for Windows](https://www.cursor.com/downloads)  
- **LM Studio**: [Download LM Studio](https://lmstudio.ai/)  
- **ngrok**: [Download ngrok](https://ngrok.com/downloads/windows)  

![Installation requirements: Cursor, LM Studio, ngrok](/assets/images/requr.png)

---

## Guide

### 1. Setup LM Studio

1. Install and launch [**LM Studio**](https://lmstudio.ai/)  .  
2. When prompted, install **Deepseek r1 7b** (recommended as of **May 1, 2025**).
Or choose any model from Cursor’s supported list:
   ![LM Studio model list with Deepseek r1 7b selected](/assets/images/aiList.png)  
3. In the left pane, click **Developer**.  
   ![Developer section in LM Studio](/assets/images/developer.png)
4. Make sure the model is loaded, click **Select a model to load** at the top of LM Studio.
5. Toggle **Status** so it reads **Running**.  
6. Click the ⚙️ **Settings** next to the status, enable **CORS**, and note the **Server Port** (e.g. `1233`).

### 2. Expose the Model with ngrok {#ngrok}

1. Make a free ngrok [account](https://dashboard.ngrok.com/signup).
2. Open [**ngrok**](https://ngrok.com/downloads/windows).
3. Authenticate ngrok:

   ```bash
   ngrok config add-authtoken YOUR_AUTHTOKEN_HERE
   ``` 
   > The Authtoken should be found [here](https://dashboard.ngrok.com/get-started/setup/windows)

4. Start tunneling to your [LM Studio port](#1-setup-lm-studio) (e.g., `1234`):

   ```bash
   ngrok http 1234
   ```

5. Copy the **Forwarding** URL (e.g. `https://abcd1234.ngrok.free.app`).  
   ![ngrok forwarding address](/assets/images/ngrok-free-app.png)

### 3. Configure Cursor

1. In Cursor, click the ⚙️ **Settings** (top-right), then **Models**.  
2. Under **OpenAI API Key**, enter `ollama`.  
3. Enable **Override OpenAI Base URL** and paste your ngrok URL, appending `/v1` [from ngrok](#ngrok) (e.g. `https://abcd1234.ngrok.free.app/v1`).  
   > **Important:** The `/v1` path ensures Cursor formats its API calls correctly.

4. Click **Verify & Save**.

![Cursor model settings with custom Base URL](/assets/images/OpenAI-API.png)

### 4. Verify

Open a new chat in Cursor and type:

```text
help me optimize the code
```

![Cursor model settings with custom Base URL](/assets/images/Cursor-Working.png)

You should receive a response without errors.

**Note Toggle the model you use in the chat section of Cursor, in my case its `deepseek-r1`.**

---

Congratulations, you’re now running Cursor AI entirely free!
